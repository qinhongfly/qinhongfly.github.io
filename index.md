---
layout: default
---

<img class="profile-picture" src="bio.jpg">

Director of R&D, [SenseTime Group Ltd.](https://www.sensetime.com/en/)  
Email: [jiangqinhong at senseauto dot com]()
<br/>

## Short Biography
---  
Currently I am a Director of R&D at SenseTime, leading the **perception team** and the **mass production testing** team in intelligent driving group.    
I am also responsible for the development of our L2+ autonomous driving system SenseAuto Pilot, as well as some mass production projects.    
Before that, I was also responsible for the prediction team.      
  
I got my M.S. degree in the [State Key Lab of CAD&CG, Zhejiang University](http://www.cad.zju.edu.cn/english.html), supervised by [Prof. Guofeng Zhang](http://www.cad.zju.edu.cn/home/gfzhang/). Before that, I received the B.S. degree of Digital Media Technology in Zhejiang University.  

We are recruiting self-motivated researchers/developers.  
<br/>
<br/>
<br/>

## R&D Interest 
---
Topics related to autonoumous driving include but are not limited to perception, sensor fusion, trajectory prediction and software engineering.   
<br/>
<br/>
<br/>


## Publications
---  
[Towards Model Generalization for Monocular 3D Object Detection](https://arxiv.org/pdf/2205.11664.pdf)   
Zhenyu Li, Zehui Chen, Ang Li, Liangji Fang, **Qinhong Jiang**, Xianming Liu, Junjun Jiang   
   
[Unsupervised Domain Adaptation for Monocular 3D Object Detection via Self-Training](https://arxiv.org/pdf/2204.11590.pdf)    
Zhenyu Li, Zehui Chen, Ang Li, Liangji Fang, **Qinhong Jiang**, Xianming Liu, and Junjun Jiang    
ECCV 2022.   
   
[Deformable Feature Aggregation for Dynamic Multi-Modal 3D Object Detection]()     
Zehui Chen, Zhenyu Li, Shiquan Zhang, Liangji Fang, **Qinhong Jiang**, Feng Zhao    
ECCV 2022.   
   
[AutoAlign: Pixel-Instance Feature Aggregation for Multi-Modal 3D Object Detection](https://arxiv.org/abs/2201.06493)    
Zehui Chen, Zhenyu Li, Shiquan Zhang, Liangji Fang, **Qinghong Jiang**, Feng Zhao, Bolei Zhou, Hang Zhao   
IJCAI 2022.   
    
[Graph-DETR3D: Rethinking Overlapping Regions for Multi-View 3D Object Detection](https://arxiv.org/pdf/2204.11582.pdf)    
Zehui Chen, Zhenyu Li, Shiquan Zhang, Liangji Fang, **Qinhong Jiang**, Feng Zhao   
ACM MM 2022.   
  
[SimIPU: Simple 2D Image and 3D Point Cloud Unsupervised Pre-Training for Spatial-Aware Visual Representations](https://arxiv.org/abs/2112.04680)  
Zhenyu Li, Zehui Chen, Ang Li, Liangji Fang, **Qinhong Jiang**, Xianming Liu, Junjun Jiang, Bolei Zhou, Hang Zhao  
AAAI 2022.    
   
[Shape Prior Guided Instance Disparity Estimation for 3D Object Detection](https://ieeexplore.ieee.org/document/9419782)  
Linghao Chen, Jiaming Sun, Yiming Xie, Siyu Zhang, Qing Shuai, **Qinhong Jiang**, Guofeng Zhang, Hujun Bao, Xiaowei Zhou  
TPAMI 2021.    

[Monocular 3D Object Detection: An Extrinsic Parameter Free Approach](https://lion.sjtu.edu.cn/resource/downloadFile?filePath=/home/lion/lionweb/data/publication/text/20210331170319_802.pdf)   
Yunsong Zhou, Yuan He, Hongzi Zhu, Cheng Wang, Hongyang Li, **Qinhong Jiang**   
CVPR 2021.     

[Multimodal Motion Prediction with Stacked Transformers](https://arxiv.org/abs/2103.11624)   
Yicheng Liu\*, Jinghuai Zhang\*, Liangji Fang, **Qinhong Jiang**, Bolei Zhou    
CVPR 2021.    

[Dynamic and Static Context-aware LSTM for Multi-agent Motion Prediction](https://arxiv.org/abs/2008.00777)    
Chaofan Tao, **Qinhong Jiang**, Lixin Duan, Luo Ping    
ECCV 2020.    

[TPNet: Trajectory Proposal Network for Motion Prediction](https://arxiv.org/abs/2004.12255)  
Liangji Fang\*, **Qinhong Jiang**\*, Jianping Shi, Bolei Zhou (\* equal contribution)      
CVPR 2020.    

[Recursive Social Behavior Graph for Trajectory Prediction](https://arxiv.org/abs/2004.10402)  
Jianhua Sun, **Qinhong Jiang**, Cewu Lu  
CVPR 2020.    

[Disp R-CNN: Stereo 3D Object Detection via Shape Prior Guided Instance Disparity Estimation](https://arxiv.org/abs/2004.03572)  
Jiaming Sun, Linghao Chen, Yiming Xie, Siyu Zhang, **Qinhong Jiang**, Xiaowei Zhou, Hujun Bao   
CVPR 2020.    
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
